{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"},{"sourceId":6874344,"sourceType":"datasetVersion","datasetId":3950227},{"sourceId":3729,"sourceType":"modelInstanceVersion","modelInstanceId":2656}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\nЦелью конкурса по классификации подтипов рака яичников UBC и выявлению выбросов (UBC-OCEAN) является классификация подтипов рака яичников. \nВы создадите модель, обученную на основе самого обширного в мире набора данных о раке яичников, состоящего из гистопатологических изображений, полученных из более чем 20 медицинских центров.\n\nВаша работа поможет повысить применимость и доступность точных диагнозов рака яичников.","metadata":{}},{"cell_type":"markdown","source":"# Description\nКарцинома яичников является наиболее смертельным видом рака женской репродуктивной системы. Существует пять распространенных подтипов рака яичников: серозная карцинома высокой степени, светлоклеточная карцинома яичников, эндометриоидная, серозная низкой степени и муцинозная карцинома. Кроме того, существует несколько редких подтипов (\"выбросов\"). Все они характеризуются различными клеточными морфологиями, этиологиями, молекулярными и генетическими профилями и клиническими признаками. Подходы к лечению, специфичные для подтипа, приобретают все большее значение, хотя сначала требуется идентификация подтипа - процесс, который можно было бы улучшить с помощью науки о данных.\n\nВ настоящее время диагностика рака яичников основывается на оценке подтипов патологами. Однако это сопряжено с рядом проблем, включая разногласия между наблюдателями и воспроизводимость диагностики. Кроме того, недостаточно обслуживаемые сообщества часто не имеют доступа к специалистам-патологоанатомам, и даже хорошо развитые сообщества сталкиваются с нехваткой патологоанатомов, обладающих опытом в области гинекологических злокачественных новообразований.\n\nМодели глубокого обучения продемонстрировали замечательное мастерство в анализе гистопатологических изображений. Однако проблемы все еще существуют, такие как потребность в значительном объеме обучающих данных, в идеале из одного источника. Технические, этические и финансовые ограничения, а также соображения конфиденциальности усложняют обучение. В этом конкурсе у вас будет доступ к самому обширному и разнообразному набору данных о раке яичников, состоящему из гистопатологических изображений из более чем 20 центров на четырех континентах.\n","metadata":{}},{"cell_type":"markdown","source":"6 октября 2023 - Дата начала.\n\n27 декабря 2023 - Крайний срок подачи заявок. Вы должны принять правила конкурса до этой даты, чтобы принять участие.\n\n27 декабря 2023 г. - Крайний срок объединения команд. Это последний день, когда участники могут присоединиться к командам или объединить их.\n\n3 января 2024 г. - Окончательный срок подачи заявок.\n\nВсе крайние сроки истекают в 11:59 по Гринвичу соответствующего дня, если не указано иное. Организаторы конкурса оставляют за собой право обновлять график проведения конкурса, если сочтут это необходимым.","metadata":{}},{"cell_type":"markdown","source":"- V6 ДОбавляем\n\n* from albumentations import HorizontalFlip, RandomBrightnessContrast # new\n* HorizontalFlip(p=0.5),  # Случайное горизонтальное отражение\n* RandomBrightnessContrast(p=0.5),  # Случайное изменение яркости/контрастности\n\n-V11\n \"valid_batch_size\": 12,(было 4)\n","metadata":{}},{"cell_type":"code","source":"# Основные модули и утилиты\nimport os         # Работа с функциональностью операционной системы\nimport gc         # Управление сборщиком мусора Python\nimport math       # Математические функции\nimport copy       # Создание копий объектов\nimport cv2\nimport time       # Работа со временем\nimport random     # Генерация случайных чисел\nimport glob       # Поиск файлов по шаблону\nfrom PIL import Image  # Работа с изображениями\nfrom matplotlib import pyplot as plt  # Визуализация данных\n\n# Обработка данных\nimport numpy as np   # Работа с массивами и матрицами\nimport pandas as pd  # Обработка и анализ табличных данных\n\n# PyTorch и связанные с ним библиотеки\nimport torch                    # Основная библиотека PyTorch\nimport torch.nn as nn           # Модули для построения нейронных сетей\nimport torch.optim as optim     # Оптимизаторы для обучения моделей\nimport torch.nn.functional as F # Функции активации и другие утилиты\nfrom torch.optim import lr_scheduler  # Планировщик скорости обучения\nfrom torch.utils.data import Dataset, DataLoader  # Утилиты для работы с данными\nfrom torch.cuda import amp      # Ускорение вычислений с помощью GPU\nimport torchvision              # Обработка изображений и предобученные модели\n\n# Вспомогательные утилиты\nimport joblib           # Сериализация объектов\nfrom tqdm import tqdm   # Прогресс-бар для циклов\nfrom collections import defaultdict  # Словари с автоматическим созданием значений по умолчанию\n\n# Scikit-Learn для обработки данных\nfrom sklearn.preprocessing import LabelEncoder      # Кодирование меток классов\nfrom sklearn.model_selection import StratifiedKFold  # Стратифицированное разбиение данных на фолды\n\n# Работа с моделями изображений\nimport timm  # Библиотека предобученных моделей для обработки изображений\n\n# Albumentations для аугментации изображений\nimport albumentations as A                  # Библиотека для аугментации изображений\nfrom albumentations.pytorch import ToTensorV2  # Преобразование изображений в тензоры PyTorch\nfrom albumentations import HorizontalFlip, RandomBrightnessContrast # new\n\n# Для цветного текста в терминале\nfrom colorama import Fore, Back, Style  # Модуль для стилизации текста в терминале\nb_ = Fore.BLUE  # Синий цвет текста\nsr_ = Style.RESET_ALL  # Сброс стиля текста\n\n# Управление предупреждениями и ошибками\nimport warnings\nwarnings.filterwarnings(\"ignore\")  # Игнорирование предупреждений\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  # Для более понятных сообщений об ошибках при работе с CUDA\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:53:51.320908Z","iopub.execute_input":"2023-11-29T20:53:51.321381Z","iopub.status.idle":"2023-11-29T20:53:59.584575Z","shell.execute_reply.started":"2023-11-29T20:53:51.321331Z","shell.execute_reply":"2023-11-29T20:53:59.583106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = {\n    \"seed\": 42,\n    \"img_size\": 2048,\n    \"model_name\": \"tf_efficientnet_b0_ns\",\n    \"num_classes\": 5,\n    \"valid_batch_size\": 12,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n}","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:53:59.586883Z","iopub.execute_input":"2023-11-29T20:53:59.591010Z","iopub.status.idle":"2023-11-29T20:53:59.599862Z","shell.execute_reply.started":"2023-11-29T20:53:59.590938Z","shell.execute_reply":"2023-11-29T20:53:59.596842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=42):\n    '''Устанавливает начальное значение  всего ноутбука при каждом запуске.\n    Это важно для ВОСПРОИЗВОДИМОСТИ результатов.'''\n    \n    np.random.seed(seed)  # Установка начального значения для генератора случайных чисел NumPy\n\n    torch.manual_seed(seed)  # Установка начального значения для генератора случайных чисел PyTorch\n\n    torch.cuda.manual_seed(seed)  # Установка начального значения для CUDA (GPU)\n\n    # При использовании CuDNN backend необходимо установить дополнительные параметры\n    torch.backends.cudnn.deterministic = True  # Гарантирует, что операции будут детерминированными\n    torch.backends.cudnn.benchmark = False    # Отключает оптимизацию производительности для детерминированных результатов\n\n    # Установка фиксированного значения для PYTHONHASHSEED\n    os.environ['PYTHONHASHSEED'] = str(seed)  # Это влияет на хеширование строк и объектов в Python\n\n# Вызов функции с начальным значением из конфигурации\nset_seed(CONFIG['seed'])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:53:59.601275Z","iopub.execute_input":"2023-11-29T20:53:59.601714Z","iopub.status.idle":"2023-11-29T20:53:59.631984Z","shell.execute_reply.started":"2023-11-29T20:53:59.601678Z","shell.execute_reply":"2023-11-29T20:53:59.630576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Данные","metadata":{}},{"cell_type":"code","source":"# данные \nROOT_DIR = '/kaggle/input/UBC-OCEAN'\nTEST_DIR = '/kaggle/input/UBC-OCEAN/test_thumbnails'\n# Модельи веса\nLABEL_ENCODER_BIN = \"/kaggle/input/ubc-efficienetnetb0-fold1of10-2048pix-thumbnails/label_encoder.pkl\"\nBEST_WEIGHT = \"/kaggle/input/ubc-efficienetnetb0-fold1of10-2048pix-thumbnails/Recall0.9178_Acc0.9437_Loss0.1685_epoch9.bin\"","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:53:59.636772Z","iopub.execute_input":"2023-11-29T20:53:59.637607Z","iopub.status.idle":"2023-11-29T20:53:59.644082Z","shell.execute_reply.started":"2023-11-29T20:53:59.637561Z","shell.execute_reply":"2023-11-29T20:53:59.642702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_file_path(image_id):\n    return f\"{TEST_DIR}/{image_id}_thumbnail.png\"","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:53:59.646272Z","iopub.execute_input":"2023-11-29T20:53:59.646995Z","iopub.status.idle":"2023-11-29T20:53:59.653792Z","shell.execute_reply.started":"2023-11-29T20:53:59.646952Z","shell.execute_reply":"2023-11-29T20:53:59.652745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f\"{ROOT_DIR}/test.csv\")\ndf['file_path'] = df['image_id'].apply(get_test_file_path)\ndf['label'] = 0 # dummy\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:53:59.655943Z","iopub.execute_input":"2023-11-29T20:53:59.656778Z","iopub.status.idle":"2023-11-29T20:53:59.692274Z","shell.execute_reply.started":"2023-11-29T20:53:59.656736Z","shell.execute_reply":"2023-11-29T20:53:59.691177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub = pd.read_csv(f\"{ROOT_DIR}/sample_submission.csv\")\ndf_sub","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:53:59.693623Z","iopub.execute_input":"2023-11-29T20:53:59.693972Z","iopub.status.idle":"2023-11-29T20:53:59.710701Z","shell.execute_reply.started":"2023-11-29T20:53:59.693942Z","shell.execute_reply":"2023-11-29T20:53:59.709662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = joblib.load( LABEL_ENCODER_BIN )","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:53:59.713135Z","iopub.execute_input":"2023-11-29T20:53:59.713506Z","iopub.status.idle":"2023-11-29T20:53:59.730833Z","shell.execute_reply.started":"2023-11-29T20:53:59.713475Z","shell.execute_reply":"2023-11-29T20:53:59.729190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cropped_images(file_path, image_id, th_area = 1000):\n    image = Image.open(file_path)# Открытие изображения\n     # Вычисление аспектного соотношения изображения\n    as_ratio = image.size[0] / image.size[1]\n    # Инициализация списков для координат кадрирования\n    sxs, exs, sys, eys = [],[],[],[]\n    # Проверка, если аспектное соотношение больше или равно 1.5\n    if as_ratio >= 1.5:\n        # Создание маски изображения\n        mask = np.max( np.array(image) > 0, axis=-1 ).astype(np.uint8)\n        retval, labels = cv2.connectedComponents(mask)\n        # Проверка условия для кадрирования\n        if retval >= as_ratio:\n            x, y = np.meshgrid( np.arange(image.size[0]), np.arange(image.size[1]) )\n            # Проход по каждому соединённому компоненту\n            for label in range(1, retval):\n                area = np.sum(labels == label)\n                if area < th_area:\n                    continue\n                xs, ys= x[ labels == label ], y[ labels == label ]\n                sx, ex = np.min(xs), np.max(xs)\n                cx = (sx + ex) // 2\n                crop_size = image.size[1]\n                # Вычисление координат для кадрирования\n                sx = max(0, cx-crop_size//2)\n                ex = min(sx + crop_size - 1, image.size[0]-1)\n                sx = ex - crop_size + 1\n                sy, ey = 0, image.size[1]-1\n                # Добавление координат в списки\n                sxs.append(sx)\n                exs.append(ex)\n                sys.append(sy)\n                eys.append(ey)\n        else:\n            crop_size = image.size[1]\n            for i in range(int(as_ratio)):\n                sxs.append( i * crop_size )\n                exs.append( (i+1) * crop_size - 1 )\n                sys.append( 0 )\n                eys.append( crop_size - 1 )\n    else:\n        # Если изображение не требует кадрирования (вся картинка)\n        sxs, exs, sys, eys = [0,],[image.size[0]-1],[0,],[image.size[1]-1]\n# Создание DataFrame для хранения информации о кадрировании\n    df_crop = pd.DataFrame()\n    df_crop[\"image_id\"] = [image_id] * len(sxs)\n    df_crop[\"file_path\"] = [file_path] * len(sxs)\n    df_crop[\"sx\"] = sxs\n    df_crop[\"ex\"] = exs\n    df_crop[\"sy\"] = sys\n    df_crop[\"ey\"] = eys\n       # Возврат \n    return df_crop","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:53:59.732906Z","iopub.execute_input":"2023-11-29T20:53:59.733319Z","iopub.status.idle":"2023-11-29T20:53:59.752797Z","shell.execute_reply.started":"2023-11-29T20:53:59.733277Z","shell.execute_reply":"2023-11-29T20:53:59.751613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs = []\nfor (file_path, image_id) in zip(df[\"file_path\"], df[\"image_id\"]):\n    dfs.append( get_cropped_images(file_path, image_id) )\n\ndf_crop = pd.concat(dfs)\ndf_crop[\"label\"] = 0 # dummy\ndf_crop","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:53:59.757471Z","iopub.execute_input":"2023-11-29T20:53:59.757897Z","iopub.status.idle":"2023-11-29T20:54:00.551165Z","shell.execute_reply.started":"2023-11-29T20:53:59.757862Z","shell.execute_reply":"2023-11-29T20:54:00.550073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_crop = df_crop.drop_duplicates(subset=[\"image_id\", \"sx\", \"ex\", \"sy\", \"ey\"]).reset_index(drop=True)\ndf_crop","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:54:00.552630Z","iopub.execute_input":"2023-11-29T20:54:00.552967Z","iopub.status.idle":"2023-11-29T20:54:00.573433Z","shell.execute_reply.started":"2023-11-29T20:54:00.552937Z","shell.execute_reply":"2023-11-29T20:54:00.572263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UBCDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        # Инициализация\n        self.df = df  # DataFrame с данными\n        self.file_names = df['file_path'].values  # Пути к файлам изображений\n        self.labels = df['label'].values  # Метки классов\n        self.transforms = transforms  # Преобразования (аугментации) изображений\n        # Координаты для кадрирования изображений\n        self.sxs = df[\"sx\"].values\n        self.exs = df[\"ex\"].values\n        self.sys = df[\"sy\"].values\n        self.eys = df[\"ey\"].values\n        \n    def __len__(self):\n        # Возвращает общее количество элементов в наборе данных\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        # Получение элемента по индексу\n        img_path = self.file_names[index]  # Путь к изображению\n        # Координаты для кадрирования\n        sx = self.sxs[index]\n        ex = self.exs[index]\n        sy = self.sys[index]\n        ey = self.eys[index]\n        img = cv2.imread(img_path)  # Чтение изображения\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Преобразование в RGB\n        label = self.labels[index]  # Метка класса\n\n        # Кадрирование изображения\n        img = img[sy:ey, sx:ex, :]\n        \n        # Применение аугментаций, если они указаны\n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        # Возвращение словаря с обработанным изображением и меткой\n        return {\n            'image': img,\n            'label': torch.tensor(label, dtype=torch.long)\n        }\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:54:00.575154Z","iopub.execute_input":"2023-11-29T20:54:00.575481Z","iopub.status.idle":"2023-11-29T20:54:00.587361Z","shell.execute_reply.started":"2023-11-29T20:54:00.575453Z","shell.execute_reply":"2023-11-29T20:54:00.586331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentations","metadata":{}},{"cell_type":"markdown","source":"A.RandomBrightnessContrast()","metadata":{}},{"cell_type":"code","source":"\n\ndata_transforms = {\n    # Изменение размера изображения\n    \"valid\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n#         HorizontalFlip(p=0.5),  # Случайное горизонтальное отражение\n#        RandomBrightnessContrast(p=0.8),  # Случайное изменение яркости/контрастности\n        # Нормализация изображения\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.230, 0.223, 0.225], max_pixel_value=255.0, p=1),\n        ToTensorV2()\n    ], p=1.)\n}","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:54:00.588572Z","iopub.execute_input":"2023-11-29T20:54:00.589574Z","iopub.status.idle":"2023-11-29T20:54:00.603989Z","shell.execute_reply.started":"2023-11-29T20:54:00.589530Z","shell.execute_reply":"2023-11-29T20:54:00.602737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_transforms = {\n#     \"valid\": A.Compose([\n#         # Изменение размера изображения\n#         A.Resize(CONFIG['img_size'], CONFIG['img_size']),      \n#         # Нормализация изображения\n#         A.Normalize(\n#             mean=[0.485, 0.456, 0.406],  # Средние значения для нормализации (стандартные для ImageNet)\n#             std=[0.230, 0.223, 0.225],   # Стандартные отклонения (стандартные для ImageNet)\n#             max_pixel_value=255.0,       # Максимальное значение пикселя\n#             p=1.0                        # Вероятность применения этого преобразования\n#         ),\n#         ToTensorV2()  # Преобразование изображения в тензор PyTorch\n#     ], p=1.)\n# }\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:54:00.605348Z","iopub.execute_input":"2023-11-29T20:54:00.606168Z","iopub.status.idle":"2023-11-29T20:54:00.618792Z","shell.execute_reply.started":"2023-11-29T20:54:00.606128Z","shell.execute_reply":"2023-11-29T20:54:00.617885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pooling","metadata":{}},{"cell_type":"markdown","source":"- Метод __init__ инициализирует модуль с заданными параметрами p и eps. Параметр p определяет степень, в которую возводятся значения пикселей перед усреднением, и он делается обучаемым параметром через nn.Parameter.\n\n- Метод forward определяет прямой проход (forward pass) модуля. Он вызывает метод gem с текущими значениями x, p и eps.\n\n- Метод gem реализует обобщённое среднее пулинга. Это делается путём возведения в степень p значений пикселей изображения, применения операции усреднения, и затем возведения результата в степень 1/p. Для стабильности вычислений используется значение eps.\n\n- Метод __repr__ предоставляет строковое представление объекта, что полезно для отладки и логирования.","metadata":{}},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"code","source":"class GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM, self).__init__()\n        # Инициализация параметра p как обучаемого параметра\n        self.p = nn.Parameter(torch.ones(1) * p)\n        # Маленькое положительное число для избегания деления на ноль\n        self.eps = eps\n\n    def forward(self, x):\n        # Определение операции прямого прохода\n        return self.gem(x, p=self.p, eps=self.eps)\n        \n    def gem(self, x, p=3, eps=1e-6):#  v4 поменял p=3.5эффект не понятен\n        # Реализация обобщённого среднего пулинга\n        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n        \n    def __repr__(self):\n        # Представление класса в виде строки\n        return self.__class__.__name__ + \\\n                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n                ', ' + 'eps=' + str(self.eps) + ')'\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:54:00.620255Z","iopub.execute_input":"2023-11-29T20:54:00.620844Z","iopub.status.idle":"2023-11-29T20:54:00.630679Z","shell.execute_reply.started":"2023-11-29T20:54:00.620809Z","shell.execute_reply":"2023-11-29T20:54:00.629575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model_v1","metadata":{}},{"cell_type":"code","source":"# class UBCModel(nn.Module):\n#     def __init__(self, model_name, num_classes, pretrained=False, checkpoint_path=None):\n#         super(UBCModel, self).__init__()\n#         # Создание модели с использованием библиотеки timm\n#         self.model = timm.create_model(model_name, pretrained=pretrained)\n\n#         # Получение количества признаков на выходе классификатора\n#         in_features = self.model.classifier.in_features\n#         # Замена классификатора и глобального пула на Identity (удаление)\n#         self.model.classifier = nn.Identity()\n#         self.model.global_pool = nn.Identity()\n#         # Добавление GeM пулинга\n#         self.pooling = GeM()\n#         # Линейный слой для классификации\n#         self.linear = nn.Linear(in_features, num_classes)\n#         # Слой Softmax для выхода вероятностей\n#         self.softmax = nn.Softmax(dim=1)\n\n#     def forward(self, images):\n#         # Прямой проход через модель\n#         features = self.model(images)\n#         # Применение GeM пулинга и сглаживание\n#         pooled_features = self.pooling(features).flatten(1)\n#         # Применение линейного слоя\n#         output = self.linear(pooled_features)\n#         return output\n\n# # Создание экземпляра модели с параметрами из конфигурации\n# model = UBCModel(CONFIG['model_name'], CONFIG['num_classes'])\n# # Загрузка предобученных весов, если они есть\n# model.load_state_dict(torch.load(BEST_WEIGHT))\n# # Перемещение модели на устройство для вычислений (например, на GPU)\n# model.to(CONFIG['device']);","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:54:00.632541Z","iopub.execute_input":"2023-11-29T20:54:00.633081Z","iopub.status.idle":"2023-11-29T20:54:00.645662Z","shell.execute_reply.started":"2023-11-29T20:54:00.633035Z","shell.execute_reply":"2023-11-29T20:54:00.644602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UBCModel(nn.Module):\n    def __init__(self, model_name, num_classes, pretrained=False, checkpoint_path=None):\n        super(UBCModel, self).__init__()\n        # Создание модели с использованием библиотеки timm\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n\n        # Получение количества признаков на выходе классификатора\n        in_features = self.model.classifier.in_features\n        # Замена классификатора и глобального пула на Identity (удаление)\n        self.model.classifier = nn.Identity()\n        self.model.global_pool = nn.Identity()\n        # Добавление GeM пулинга\n        self.pooling = GeM()\n        # Линейный слой для классификации\n        self.linear = nn.Linear(in_features, num_classes)\n        \n        #***********************************************\n        self.batch_norm = nn.BatchNorm1d(num_classes)  # Добавление Batch Normalization\n        self.dropout = nn.Dropout(0.55)  # Добавление Dropout\n        #***********************************************\n        # Слой Softmax для выхода вероятностей\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, images):\n        # Прямой проход через модель\n        features = self.model(images)\n        # Применение GeM пулинга и сглаживание\n        pooled_features = self.pooling(features).flatten(1)\n        # Применение линейного слоя\n        output = self.linear(pooled_features)\n        \n        #***********************************************\n        output = self.batch_norm(output)  # Применение Batch Normalization\n        output = self.dropout(output)     # Применение Dropout\n        #***********************************************\n        return output\n\n# Создание экземпляра модели с параметрами из конфигурации\nmodel = UBCModel(CONFIG['model_name'], CONFIG['num_classes'])\n# Загрузка предобученных весов, если они есть\nmodel.load_state_dict(torch.load(BEST_WEIGHT))\n# Перемещение модели на устройство для вычислений (например, на GPU)\nmodel.to(CONFIG['device']);\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T19:38:16.288375Z","iopub.execute_input":"2023-12-04T19:38:16.288774Z","iopub.status.idle":"2023-12-04T19:38:16.611959Z","shell.execute_reply.started":"2023-12-04T19:38:16.288741Z","shell.execute_reply":"2023-12-04T19:38:16.610490Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mUBCModel\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name, num_classes, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, checkpoint_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(UBCModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"],"ename":"NameError","evalue":"name 'nn' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Создание объекта тестового набора данных\ntest_dataset = UBCDataset(df_crop, transforms=data_transforms[\"valid\"])\n\n# Создание загрузчика данных для тестового набора\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=CONFIG['valid_batch_size'],  # Размер пакета данных\n    num_workers=6,                          # Количество рабочих процессов для загрузки данных\n    shuffle=False,                          # Отсутствие перемешивания данных v4 false\n    pin_memory=True                         # Предварительное выделение памяти, ускоряет передачу данных на GPU\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:54:01.962310Z","iopub.status.idle":"2023-11-29T20:54:01.962747Z","shell.execute_reply.started":"2023-11-29T20:54:01.962530Z","shell.execute_reply":"2023-11-29T20:54:01.962550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Инициализация списка для сохранения предсказаний\npreds = []\n\n# Блокировка вычисления градиентов для экономии памяти и ускорения\nwith torch.no_grad():\n    # Итерирование по тестовым данным с отображением прогресса\n    bar = tqdm(enumerate(test_loader), total=len(test_loader))\n    for step, data in bar:        \n        # Перемещение изображений на устройство (например, GPU) и приведение к типу float\n        images = data['image'].to(CONFIG[\"device\"], dtype=torch.float)        \n        # Получение размера пакета\n        batch_size = images.size(0)\n        # Вычисление предсказаний модели\n        outputs = model(images)\n        # Применение функции softmax для получения вероятностей классов\n        outputs = model.softmax(outputs)\n        # Добавление предсказаний в список preds\n        preds.append(outputs.detach().cpu().numpy())\n\n# Объединение результатов из разных пакетов в один массив\npreds = np.vstack(preds)\nprint(preds.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:54:01.964782Z","iopub.status.idle":"2023-11-29T20:54:01.965206Z","shell.execute_reply.started":"2023-11-29T20:54:01.964995Z","shell.execute_reply":"2023-11-29T20:54:01.965030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Добавление вероятностей каждого класса в DataFrame\nfor i in range(preds.shape[-1]):\n    df_crop[f\"cat{i}\"] = preds[:, i]\n\n# Инициализация словаря для окончательных предсказаний\ndict_label = {}\n\n# Группировка DataFrame по ID изображения и вычисление окончательного предсказания для каждого изображения\nfor image_id, gdf in df_crop.groupby(\"image_id\"):\n    # Выбор класса с максимальной вероятностью\n    #dict_label[image_id] = np.argmax(gdf[[f\"cat{i}\" for i in range(preds.shape[-1])]].values.max(axis=0))\n    # Альтернативный вариант: использование среднего значения вероятностей классов\n    dict_label[image_id] = np.argmax(gdf[[f\"cat{i}\" for i in range(preds.shape[-1])]].values.mean(axis=0))\n\n# Создание массива окончательных предсказаний, используя ID изображений из исходного DataFrame\npreds = np.array([dict_label[image_id] for image_id in df[\"image_id\"].values])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:54:01.967252Z","iopub.status.idle":"2023-11-29T20:54:01.967929Z","shell.execute_reply.started":"2023-11-29T20:54:01.967724Z","shell.execute_reply":"2023-11-29T20:54:01.967747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# submission","metadata":{}},{"cell_type":"code","source":"# Использование обратного преобразования LabelEncoder для получения исходных текстовых меток\npred_labels = encoder.inverse_transform(preds)\n\n# Присвоение этих меток в соответствующий столбец DataFrame\ndf_sub[\"label\"] = pred_labels\n\n# Сохранение DataFrame в файл CSV без индекса\ndf_sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:54:01.969547Z","iopub.status.idle":"2023-11-29T20:54:01.970630Z","shell.execute_reply.started":"2023-11-29T20:54:01.970342Z","shell.execute_reply":"2023-11-29T20:54:01.970371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub","metadata":{"execution":{"iopub.status.busy":"2023-11-29T20:54:01.971891Z","iopub.status.idle":"2023-11-29T20:54:01.972915Z","shell.execute_reply.started":"2023-11-29T20:54:01.972620Z","shell.execute_reply":"2023-11-29T20:54:01.972648Z"},"trusted":true},"execution_count":null,"outputs":[]}]}