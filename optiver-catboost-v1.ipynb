{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"},{"sourceId":6941738,"sourceType":"datasetVersion","datasetId":3986474},{"sourceId":6991591,"sourceType":"datasetVersion","datasetId":4018611}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Обзор\nВ этом соревновании перед вами стоит задача разработать модель, способную предсказать движение цен на закрытие для сотен акций, котирующихся на бирже Nasdaq, используя данные из книги заказов и аукциона на закрытие акции. Информация с аукциона может быть использована для корректировки цен, оценки динамики спроса и предложения и определения торговых возможностей.","metadata":{}},{"cell_type":"markdown","source":"## Описание\n\n- Фондовые биржи - это быстро развивающаяся среда с высокими ставками, где важна каждая секунда. Напряженность возрастает по мере приближения торгового дня к концу, достигая пика в критические последние десять минут. Эти моменты, часто характеризующиеся повышенной волатильностью и быстрыми колебаниями цен, играют ключевую роль в формировании глобальной экономической картины дня.\n\n- Каждый торговый день на фондовой бирже Nasdaq завершается закрытием перекрестного аукциона Nasdaq. Этот процесс устанавливает официальные цены закрытия для ценных бумаг, котирующихся на бирже. Эти цены закрытия служат ключевыми показателями для инвесторов, аналитиков и других участников рынка при оценке эффективности отдельных ценных бумаг и рынка в целом.\n\n- В рамках этого сложного финансового ландшафта работает Optiver, ведущий мировой производитель электронных товаров. Благодаря технологическим инновациям Optiver торгует широким спектром финансовых инструментов, таких как деривативы, наличные акции, ETF, облигации и иностранная валюта, предлагая конкурентоспособные двусторонние цены на тысячи этих инструментов на крупнейших биржах по всему миру.\n\n- В последние десять минут торговой сессии на бирже Nasdaq маркетмейкеры, такие как Optiver, объединяют данные традиционной книги заказов с данными аукционной книги. Эта возможность консолидировать информацию из обоих источников имеет решающее значение для предоставления наилучших цен всем участникам рынка.\n\n- В этом конкурсе перед вами стоит задача разработать модель, способную предсказать динамику цен на закрытие для сотен акций, котирующихся на бирже Nasdaq, используя данные из книги заказов и аукциона по закрытию акций. Информация с аукциона может быть использована для корректировки цен, оценки динамики спроса и предложения и определения торговых возможностей.\n\n- Ваша модель может способствовать консолидации сигналов с аукциона и книги заявок, что приведет к повышению эффективности и доступности рынка, особенно в течение напряженных последних десяти минут торгов. Вы также получите непосредственный опыт решения реальных задач в области обработки данных\n","metadata":{}},{"cell_type":"code","source":"import os      # Для взаимодействия с операционной системой\nimport gc      # Для управления сборщиком мусора\nimport time    # Для работы со временем\nimport warnings\nfrom warnings import simplefilter  # Для управления предупреждениями\nfrom itertools import combinations  # Для создания комбинаций элементов\n\n\nimport joblib  # Для сериализации и десериализации моделей и других объектов\nimport numpy as np  # Библиотека для работы с массивами\nimport pandas as pd  # Библиотека для работы с табличными данными\n\n\nfrom catboost import CatBoostRegressor, EShapCalcType, EFeaturesSelectionAlgorithm  # Библиотека CatBoost для построения моделей градиентного бустинга\nimport lightgbm as lgb  # Библиотека LightGBM для градиентного бустинга\nfrom sklearn.model_selection import KFold, TimeSeriesSplit  # Инструменты для кросс-валидации\n\nfrom sklearn.metrics import mean_absolute_error  # Метрика для оценки качества моделей\n\nfrom numba import njit, prange  # Для оптимизации вычислений через JIT-компиляцию\n\nimport seaborn as sns  # Библиотека для статистической визуализации\nimport matplotlib.pyplot as plt  # Библиотека для построения графиков\n\nwarnings.filterwarnings(\"ignore\")  # Игнорирование предупреждений\nsimplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)  # Игнорирование специфических предупреждений pandas\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T23:35:20.975529Z","iopub.execute_input":"2023-12-01T23:35:20.975950Z","iopub.status.idle":"2023-12-01T23:35:27.021401Z","shell.execute_reply.started":"2023-12-01T23:35:20.975917Z","shell.execute_reply":"2023-12-01T23:35:27.020367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!jupyter nbextension enable --py widgetsnbextension","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:35:27.023514Z","iopub.execute_input":"2023-12-01T23:35:27.024727Z","iopub.status.idle":"2023-12-01T23:35:28.706361Z","shell.execute_reply.started":"2023-12-01T23:35:27.024690Z","shell.execute_reply":"2023-12-01T23:35:28.704292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"is_offline: Если True, программа работает в офлайновом режиме, что обычно означает использование локальных данных и возможность разделения на обучающие и тестовые наборы данных. Если False, предполагается онлайновый режим, при котором вся доступная информация используется для обучения или инференса без разделения на поднаборы.\n\nis_train: Этот флаг указывает, находится ли программа в режиме обучения. Если True, программа будет выполнять операции, связанные с обучением моделей.\n\nis_infer: Флаг для инференса, то есть применения обученной модели для получения предсказаний на новых данных.\n\nsplit_day: Это значение используется для разделения временного ряда на различные наборы данных, например, на обучающий и тестовый наборы. В данном случае, все данные до дня 535 будут использоваться для одной цели (например, обучения), а данные после - для другой (например, тестирования или валидации).","metadata":{}},{"cell_type":"code","source":"# Настройка параметров\nis_offline = False    # Флаг для выбора режима работы: онлайн (False) или офлайн (True)\nis_train = True       # Флаг для выбора режима обучения: True для обучения, False для других целей\nis_infer = True       # Флаг для выбора режима вывода (инференса): True для вывода, False в противном случае\n#***** 435\nsplit_day = 435       # День для разделения временного ряда на обучающий и тестовый/вали","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:35:28.709458Z","iopub.execute_input":"2023-12-01T23:35:28.710631Z","iopub.status.idle":"2023-12-01T23:35:28.718253Z","shell.execute_reply.started":"2023-12-01T23:35:28.710545Z","shell.execute_reply":"2023-12-01T23:35:28.716365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")\ndf = df.dropna(subset=[\"target\"])\ndf.reset_index(drop=True, inplace=True)\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:35:28.722646Z","iopub.execute_input":"2023-12-01T23:35:28.723211Z","iopub.status.idle":"2023-12-01T23:35:52.423734Z","shell.execute_reply.started":"2023-12-01T23:35:28.723169Z","shell.execute_reply":"2023-12-01T23:35:52.422327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Функция для вычисления дисбаланса трех значений\n@njit(parallel=True)\ndef compute_triplet_imbalance(df_values, comb_indices):\n    num_rows = df_values.shape[0]\n    num_combinations = len(comb_indices)\n    imbalance_features = np.empty((num_rows, num_combinations))\n\n    for i in prange(num_combinations):\n        a, b, c = comb_indices[i]\n        \n        for j in range(num_rows):\n            # Вычисление максимального, среднего и минимального значений\n            max_val = max(df_values[j, a], df_values[j, b], df_values[j, c])\n            min_val = min(df_values[j, a], df_values[j, b], df_values[j, c])\n            mid_val = df_values[j, a] + df_values[j, b] + df_values[j, c] - min_val - max_val\n            \n            # Предотвращение деления на ноль\n            if mid_val == min_val:\n                imbalance_features[j, i] = np.nan\n            else:\n                # Вычисление дисбаланса\n                imbalance_features[j, i] = (max_val - mid_val) / (mid_val - min_val)\n\n    return imbalance_features\n\n# Функция для расчета дисбаланса по всем комбинациям троек столбцов\ndef calculate_triplet_imbalance_numba(price, df):\n    df_values = df[price].values\n    comb_indices = [(price.index(a), price.index(b), price.index(c)) for a, b, c in combinations(price, 3)]\n\n    # Вызов функции compute_triplet_imbalance\n    features_array = compute_triplet_imbalance(df_values, comb_indices)\n\n    # Формирование DataFrame с результатами\n    columns = [f\"{a}_{b}_{c}_imb2\" for a, b, c in combinations(price, 3)]\n    features = pd.DataFrame(features_array, columns=columns)\n\n    return features\n\n# Функция для вычисления скользящего среднего\n@njit(fastmath=True)\ndef rolling_average(arr, window):\n    n = len(arr)\n    result = np.empty(n)\n    result[:window] = np.nan  # Заполнение начальных значений NaN\n    cumsum = np.cumsum(arr)\n\n    for i in range(window, n):\n        result[i] = (cumsum[i] - cumsum[i - window]) / window\n\n    return result\n\n# Функция для параллельного вычисления скользящих средних для разных размеров окон\n@njit(parallel=True)\ndef compute_rolling_averages(df_values, window_sizes):\n    num_rows, num_features = df_values.shape\n    \n    num_windows = len(window_sizes)+14 # -5!!\n    rolling_features = np.empty((num_rows, num_features, num_windows))\n\n    for feature_idx in prange(num_features):\n        for window_idx, window in enumerate(window_sizes):\n            # Вычисление скользящего среднего для каждого окна\n            rolling_features[:, feature_idx, window_idx] = rolling_average(df_values[:, feature_idx], window)\n\n    return rolling_features\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:35:52.425656Z","iopub.execute_input":"2023-12-01T23:35:52.426080Z","iopub.status.idle":"2023-12-01T23:35:52.532883Z","shell.execute_reply.started":"2023-12-01T23:35:52.426044Z","shell.execute_reply":"2023-12-01T23:35:52.531903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if is_offline:\n    # Если программа работает в офлайновом режиме, разделить данные на обучающий и валидационный наборы.\n    # Разделение происходит на основе значения переменной split_day.\n    df_train = df[df[\"date_id\"] <= split_day]\n    df_valid = df[df[\"date_id\"] > split_day]\n    \n    # Вывод сообщения об офлайновом режиме и размерах обучающего и валидационного наборов данных.\n    print(\"Offline mode\")\n    print(f\"train : {df_train.shape}, valid : {df_valid.shape}\")\nelse:\n    # Если программа работает в онлайновом режиме, использовать весь набор данных для обучения.\n    df_train = df\n    \n    # Вывод сообщения об онлайновом режиме.\n    print(\"Online mode\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:35:52.534395Z","iopub.execute_input":"2023-12-01T23:35:52.534813Z","iopub.status.idle":"2023-12-01T23:35:52.544574Z","shell.execute_reply.started":"2023-12-01T23:35:52.534777Z","shell.execute_reply":"2023-12-01T23:35:52.542892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Этот блок кода используется для создания глобальных характеристик по каждому stock_id в обучающем наборе данных, если программа находится в режиме обучения (is_train).**","metadata":{}},{"cell_type":"code","source":"if is_train:\n    # Создание словаря глобальных характеристик для каждого stock_id, если находимся в режиме обучения.\n    global_stock_id_feats = {\n        # Медиана размеров заявок (bid_size + ask_size) для каждого stock_id.\n        \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median() + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n        # Стандартное отклонение размеров заявок для каждого stock_id.\n        \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std() + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n        # Размах размеров заявок (максимальный - минимальный) для каждого stock_id.\n        \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max() - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n        # Медиана цен заявок (bid_price + ask_price) для каждого stock_id.\n        \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median() + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n        # Стандартное отклонение цен заявок для каждого stock_id.\n        \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std() + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n        # Размах цен заявок (максимальная - минимальная) для каждого stock_id.\n        \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max() - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n    }\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:35:52.546521Z","iopub.execute_input":"2023-12-01T23:35:52.546996Z","iopub.status.idle":"2023-12-01T23:35:54.279786Z","shell.execute_reply.started":"2023-12-01T23:35:52.546956Z","shell.execute_reply":"2023-12-01T23:35:54.278134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imbalance_features_lgbm(df):\n    # Определение списков названий столбцов, связанных с ценой и размером\n    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n    # Расчет объема и средней цены\n    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n    # Расчет различных видов дисбаланса\n    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n    df[\"matched_imbalance\"] = df.eval(\"(imbalance_size-matched_size)/(matched_size+imbalance_size)\")\n    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n    # Расчет дисбаланса для всех комбинаций цен\n    for c in combinations(prices, 2):\n        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n    # Расчет дисбаланса для определенных групп столбцов\n    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n        df[triplet_feature.columns] = triplet_feature.values\n    # Расчет дополнительных фичей дисбаланса\n    df[\"imbalance_momentum\"] = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size']\n    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n    df[\"spread_intensity\"] = df.groupby(['stock_id'])['price_spread'].diff()\n    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n    df['market_urgency'] = df['price_spread'] * df['liquidity_imbalance']\n    df['depth_pressure'] = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price'])\n    # Расчет статистических агрегаций\n    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n    # Создание смещенных и процентных фичей\n    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n        for window in [1, 2, 3, 10]:\n            df[f\"{col}_shift_{window}\"] = df.groupby('stock_id')[col].shift(window)\n            df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window)\n    # Расчет разности значений для определенных столбцов\n    for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size', 'market_urgency', 'imbalance_momentum', 'size_imbalance']:\n        for window in [1, 2, 3, 10]:\n            df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window)\n    # Замена бесконечных значений на ноль\n    return df.replace([np.inf, -np.inf], 0)\n\ndef other_features_lgbm(df):\n    # Расчет дней недели, секунд и минут\n    df[\"dow\"] = df[\"date_id\"] % 5  # День недели\n    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60\n    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60\n    # Применение глобальных фичей для каждого stock_id\n    for key, value in global_stock_id_feats.items():\n        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n    return df\n\ndef generate_all_features_lgbm(df):\n    # Выборка релевантных столбцов для генерации фич\n    cols = [c for c in df.columns if c not in [\"row_id\", \"time_id\", \"target\"]]\n    df = df[cols]\n    # Генерация фич дисбаланса и других фич\n    df = imbalance_features_lgbm(df)\n    df = other_features_lgbm(df)\n    gc.collect()  # Очистка памяти\n    # Формирование списка имен фич\n    feature_name = [i for i in df.columns if i not in [\"row_id\", \"target\", \"time_id\", \"date_id\"]]\n    return df[feature_name]\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:35:54.281797Z","iopub.execute_input":"2023-12-01T23:35:54.282355Z","iopub.status.idle":"2023-12-01T23:35:54.308307Z","shell.execute_reply.started":"2023-12-01T23:35:54.282307Z","shell.execute_reply":"2023-12-01T23:35:54.306763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_models_from_folder(model_save_path, num_folds=5):\n    loaded_models = []\n\n    # Загрузка моделей для каждого фолда (части данных)\n    for i in range(1, num_folds + 1):\n         # Составление пути к файлу модели\n        model_filename = os.path.join(model_save_path, f'doblez_{i}.txt')\n        # Проверка существования файла модели и его загрузка\n        if os.path.exists(model_filename):\n            loaded_model = lgb.Booster(model_file=model_filename)\n            loaded_models.append(loaded_model)\n            print(f\"Модель для фолда {i} загружена из {model_filename}\")\n        else:\n            print(f\"Файл модели {model_filename} не найден.\")\n\n     # Загрузка финальной модели\n    final_model_filename = os.path.join(model_save_path, 'doblez-conjunto.txt')\n    if os.path.exists(final_model_filename):\n        final_model = lgb.Booster(model_file=final_model_filename)\n        loaded_models.append(final_model)\n        print(f\"Финальная модель загружена из {final_model_filename}\")\n    else:\n        print(f\"Файл финальной модели {final_model_filename} не найден.\")\n        \n#         # Создание модели CatBoost с параметрами по умолчанию\n#     catboost_model = CatBoostRegressor()  # Или CatBoostRegressor для регрессии\n#     loaded_models.append(catboost_model)\n#     print(\"Модель CatBoost с параметрами по умолчанию добавлена.\")    \n    \n    return loaded_models\n\n# использования функции для загрузки моделей из списка папок\nfolders = [\n    '/kaggle/input/lightgbm-models/modelitos_para_despues',\n    '/kaggle/input/ensemble-of-models/results/modelitos_para_despues',\n    '/kaggle/input/ensemble-of-models/results (1)/modelitos_para_despues',\n    '/kaggle/input/ensemble-of-models/results (2)/modelitos_para_despues',\n    '/kaggle/input/ensemble-of-models/results (3)/modelitos_para_despues',\n     '/kaggle/input/ensemble-of-models/results (4)/modelitos_para_despues',\n     '/kaggle/input/ensemble-of-models/results (5)/modelitos_para_despues',\n    '/kaggle/input/ensemble-of-models/results (6)/modelitos_para_despues',\n    '/kaggle/input/ensemble-of-models/results (7)/modelitos_para_despues',\n]\nnum_folds = 7# 10\nall_loaded_models = []\nfor folder in folders:\n    all_loaded_models.extend(load_models_from_folder(folder))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:35:54.310504Z","iopub.execute_input":"2023-12-01T23:35:54.311068Z","iopub.status.idle":"2023-12-01T23:38:29.368049Z","shell.execute_reply.started":"2023-12-01T23:35:54.311032Z","shell.execute_reply":"2023-12-01T23:38:29.366267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# моделей\nnumber_of_models = len(all_loaded_models)\nprint(f\"Количество загруженных моделей: {number_of_models}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:38:29.375893Z","iopub.execute_input":"2023-12-01T23:38:29.378886Z","iopub.status.idle":"2023-12-01T23:38:29.394056Z","shell.execute_reply.started":"2023-12-01T23:38:29.378826Z","shell.execute_reply":"2023-12-01T23:38:29.389378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # названия\n# for model in all_loaded_models:\n#     print(type(model))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:38:29.397847Z","iopub.execute_input":"2023-12-01T23:38:29.398546Z","iopub.status.idle":"2023-12-01T23:38:29.413318Z","shell.execute_reply.started":"2023-12-01T23:38:29.398499Z","shell.execute_reply":"2023-12-01T23:38:29.410791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"|вес | score | версия |\n|-------------|-------------|-------------|\n|  0.15   | 5.34   |   7  |\n|  0.024  | 5.33  |  8  |\n|  0.02   | 5.3388   |   9  |\n|  0.021   |5.3389    |  10 |\n|  0.012   | 5.3386   |   11  |\n|  0.019   |5.3388    |   12  |\n|  0.011   |  86   | 13   |\n|  0.010   |  86  | 14   |\n|  0.009   |  86   | 15   |\n|  0.008   |  85   | 16   |\n|  0.005   |  85   | 17   |+\n|  0.001   |     | 18   |\n|  0.002   |     | 19   |\n|  0.003   |     | 20   |\n|  0.004   |     | 21   |\n|  0.005   |     | 22   |\n\n","metadata":{}},{"cell_type":"code","source":"# Предположим, что all_loaded_models - ваш список моделей\n# Начальное определение равных весов для всех моделей\nmodel_weights = [1 / len(all_loaded_models)] * len(all_loaded_models)\n\n# Изменение весов у каждой второй модели\nnew_weight = 0.005  # Новый вес для каждой второй модели \nfor i in range(1, len(all_loaded_models), 2):\n    model_weights[i] = new_weight\n\n# Расчет общей суммы весов после изменения\ntotal_weight = sum(model_weights)\n\n# Корректировка весов остальных моделей\nif total_weight != 1:\n    scale_factor = 1 / total_weight\n    model_weights = [w * scale_factor for w in model_weights]\n\n# Проверка, что сумма весов равна 1\nassert abs(sum(model_weights) - 1) < 1e-6, \"Сумма весов не равна 1\"","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:38:29.418223Z","iopub.execute_input":"2023-12-01T23:38:29.419032Z","iopub.status.idle":"2023-12-01T23:38:29.438443Z","shell.execute_reply.started":"2023-12-01T23:38:29.418904Z","shell.execute_reply":"2023-12-01T23:38:29.436937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Печать текущих весов\nprint(\"Текущие веса моделей:\")\nfor i, weight in enumerate(model_weights):\n    print(f\"Модель {i}: Вес = {weight}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:38:29.440448Z","iopub.execute_input":"2023-12-01T23:38:29.441275Z","iopub.status.idle":"2023-12-01T23:38:29.456204Z","shell.execute_reply.started":"2023-12-01T23:38:29.441200Z","shell.execute_reply":"2023-12-01T23:38:29.454505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #  изменить вес первой и третьей моделей\n# model_weights[0] = 0.2  # Новый вес для первой модели\n# model_weights[2] = 0.15 # Новый вес для третьей модели","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:38:29.458976Z","iopub.execute_input":"2023-12-01T23:38:29.459765Z","iopub.status.idle":"2023-12-01T23:38:29.472557Z","shell.execute_reply.started":"2023-12-01T23:38:29.459687Z","shell.execute_reply":"2023-12-01T23:38:29.470070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# После изменения весов, корректируем остальные веса, чтобы сумма была равна 1\ntotal_weight = sum(model_weights)\nif total_weight != 1:\n    scale_factor = 1 / total_weight\n    model_weights = [w * scale_factor for w in model_weights]\n\n# Проверка, что сумма весов равна 1\nassert abs(sum(model_weights) - 1) < 1e-6, \"Сумма весов не равна 1\"","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:38:29.474984Z","iopub.execute_input":"2023-12-01T23:38:29.476029Z","iopub.status.idle":"2023-12-01T23:38:29.497980Z","shell.execute_reply.started":"2023-12-01T23:38:29.475946Z","shell.execute_reply":"2023-12-01T23:38:29.494948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Печать обновленных весов\nprint(\"Обновленные веса моделей:\")\nfor i, weight in enumerate(model_weights):\n    print(f\"Модель {i}: Вес = {weight}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:38:29.500863Z","iopub.execute_input":"2023-12-01T23:38:29.501424Z","iopub.status.idle":"2023-12-01T23:38:29.519620Z","shell.execute_reply.started":"2023-12-01T23:38:29.501356Z","shell.execute_reply":"2023-12-01T23:38:29.516716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(model_weights)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:38:29.524960Z","iopub.execute_input":"2023-12-01T23:38:29.525731Z","iopub.status.idle":"2023-12-01T23:38:29.541710Z","shell.execute_reply.started":"2023-12-01T23:38:29.525680Z","shell.execute_reply":"2023-12-01T23:38:29.539458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submissions","metadata":{}},{"cell_type":"code","source":"import time  # Импорт модуля для работы со временем\n\ndef zero_sum(prices, volumes):\n    # Функция для корректировки предсказаний так, чтобы их сумма была равна нулю\n    std_error = np.sqrt(volumes)  # Вычисление стандартной ошибки\n    step = np.sum(prices) / np.sum(std_error)  # Расчет шага корректировки\n    out = prices - std_error * step  # Корректировка цен\n    return out  # Возврат скорректированных цен\n\n# Инференс\nif is_infer:\n    import optiver2023  # Импорт среды соревнования\n    env = optiver2023.make_env()  # Настройка среды для соревнования\n    iter_test = env.iter_test()   # Получение итератора для тестового набора данных\n    counter = 0                   # Инициализация счетчика\n    y_min, y_max = -64, 64        # Установка границ предсказаний\n    qps = []                      # Отслеживание запросов в секунду\n    cache = pd.DataFrame()        # Инициализация кеша для хранения тестовых данных    \n    \n    \n    \n#     # Начальное определение равных весов для всех модел\n#      model_weights = [1/len(all_loaded_models)] * len(all_loaded_models)  # Веса моделей\n#     # Изменение весов у каждой второй модели\n#     new_weight = 0.025  # Новый вес для каждой второй модели\n#     for i in range(1, len(all_loaded_models), 2):  # Пропускаем одну модель и изменяем следующую\n#         model_weights[i] = new_weight\n        \n#     # Корректировка весов остальных моделей\n#     total_weight = sum(model_weights)\n#     for i in range(len(all_loaded_models)):\n#         if i % 2 == 0:  # Для моделей, чей вес не был изменен\n#             model_weights[i] = model_weights[i] * (1 - total_weight) / sum(model_weights[::2])\n\n#     # Убедимся, что сумма весов равна 1\n#     assert abs(sum(model_weights) - 1) < 1e-6, \"Сумма весов не равна 1\"\n    \n    \n    \n    \n# #     *******************************************\n#   # Начальное задание весов\n#     model_weights = [1/len(all_loaded_models)] * len(all_loaded_models)\n\n#     # Изменение весов только для моделей CatBoost\n\n\n#     # Устанавливаем новый вес для моделей CatBoost и считаем сумму весов\n#     new_catboost_weight = 0.05\n#     total_weight = 0\n#     for i, model in enumerate(all_loaded_models):\n#         if isinstance(model, CatBoostRegressor):\n#             model_weights[i] = new_catboost_weight\n#         total_weight += model_weights[i]\n\n#     # Корректировка весов остальных моделей\n#     remaining_weight = 1 - total_weight\n#     for i, model in enumerate(all_loaded_models):\n#         if not isinstance(model, CatBoostRegressor):\n#             model_weights[i] *= remaining_weight / (1 - new_catboost_weight * len([m for m in all_loaded_models if isinstance(m, CatBoostRegressor)]))\n\n\n#     # Создание DataFrame для документирования изменений\n#     columns = ['Model Type', 'Weight', 'Performance Metric']\n#     model_info = pd.DataFrame(columns=columns)\n    \n#     # Заполнение метрик производительности\n#     performance_metrics = []\n#     catboost_performance = 0.95  # Пример метрики производительности для CatBoost\n#     lightgbm_performance = 0.85  # Пример метрики производительности для LightGBM\n    \n#     for model in all_loaded_models:\n#         if isinstance(model, CatBoostRegressor):\n#             performance_metrics.append(catboost_performance)\n#         else:\n#             performance_metrics.append(lightgbm_performance)\n\n#     # Добавление информации о каждой модели\n#     rows = []\n#     for i, model in enumerate(all_loaded_models):\n#         model_type = type(model).__name__\n#         weight = model_weights[i]\n#         performance = performance_metrics[i]\n\n#         rows.append({'Model Type': model_type,\n#                      'Weight': weight,\n#                      'Performance Metric': performance})\n\n#     # Обновление DataFrame\n#     model_info = pd.concat([model_info, pd.DataFrame(rows)], ignore_index=True)\n\n#     # Вывод таблицы\n#     print(model_info)\n#     #     *******************************************\n     \n    \n    for (test_df, revealed_targets, sample_prediction_df) in iter_test:\n        test_df = test_df.drop('currently_scored', axis=1)  # Удаление лишнего столбца\n        now_time = time.time()  # Текущее время для измерения производительности\n        print('counter:', counter)\n        # Объединение новых тестовых данных с кешем, сохранение последних 21 наблюдений для каждого stock_id\n        cache = pd.concat([cache, test_df], ignore_index=True, axis=0)\n        if counter > 0:\n            cache = cache.groupby('stock_id').tail(21).reset_index(drop=True)\n        \n        feat = generate_all_features_lgbm(cache)[-len(test_df):]  # Генерация признаков\n        pred = model_weights[0] * all_loaded_models[0].predict(feat)  # Предсказание первой модели\n        \n        # Генерация предсказаний для каждой модели и расчет взвешенного среднего\n        for model, weight in zip(all_loaded_models[1:], model_weights[1:]):\n            pred += weight * model.predict(feat)\n        \n        # Применение функции zero_sum и ограничение предсказаний\n        pred = zero_sum(pred, test_df['bid_size'] + test_df['ask_size'])\n        clipped_predictions = np.clip(pred, y_min, y_max)  # Ограничение предсказаний\n        \n        # Установка предсказаний в sample_prediction_df\n        sample_prediction_df['target'] = clipped_predictions\n        \n        # Использование среды для выполнения предсказаний\n        env.predict(sample_prediction_df)\n        \n        counter += 1  # Увеличение счетчика\n        qps.append(time.time() - now_time)  # Добавление времени запроса\n        \n        if counter % 10 == 0:\n            print(f\"{counter} queries per second: {np.mean(qps)}\")  # Вывод среднего времени запросов\n\n    time_cost = 1.146 * np.mean(qps)  # Расчет ожидаемого времени выполнения\n    print(f\"The code will take approximately {np.round(time_cost, 2)} hours to reason about\")  # Вывод ожидаемого времени\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T23:38:29.545619Z","iopub.execute_input":"2023-12-01T23:38:29.546059Z","iopub.status.idle":"2023-12-01T23:38:38.855550Z","shell.execute_reply.started":"2023-12-01T23:38:29.546029Z","shell.execute_reply":"2023-12-01T23:38:38.853332Z"},"trusted":true},"execution_count":null,"outputs":[]}]}